{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import xgboost as xgb\n",
    "import pickle\n",
    "import warnings\n",
    "\n",
    "# Ignore PerformanceWarning and UserWarning\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=pd.errors.PerformanceWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "player_match_df = pd.read_csv('datasets\\player_match_df_clean.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now look at the size of our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95207, 296)"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "player_match_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a lot of features to work with here, so will we look to reduce these before building our model.\n",
    "\n",
    "However, first we will look at removing a section of the most recent data to use as an evaluation dataset, so that we can hypothetically look at how profitable the model would have been if we had built it several years ago:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of dataset where matches took place in 2023 or 2024: 12.24%\n"
     ]
    }
   ],
   "source": [
    "pct_23_24 = round((player_match_df['year'].isin([2023, 2024, 2025]).sum() / len(player_match_df)) * 100, 2)\n",
    "print(f'Percentage of dataset where matches took place in 2023 or 2024: {pct_23_24}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the 2023-2025 data accounts for around 12% of our data, this is a good chunk to evaluate our model with so we will remove this from the dataset now for later use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract 2024 data and save as file \n",
    "player_match_df_23_25 = player_match_df[player_match_df['year'].isin([2023,2024,2025])]\n",
    "player_match_df_23_25.to_csv('datasets\\player_match_df_23_25.csv', index=False)\n",
    "\n",
    "# Remove 2024 data from original dataset\n",
    "player_match_df = player_match_df[~(player_match_df['year'].isin([2023,2024,2025]))]\n",
    "\n",
    "# Reset index\n",
    "player_match_df = player_match_df.reset_index(drop=True)\n",
    "player_match_df.to_csv('datasets\\player_match_df_reduced.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to extract odds from dataset\n",
    "\n",
    "Next we will extract the bookmaker odds from our dataset, as we don't want to use these for our model training but they will be of interest for our model evaluation.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_odds_df(df):\n",
    "    \"\"\"\n",
    "    Extracts a simplified DataFrame containing only the 'odds' and 'won' columns.\n",
    "\n",
    "    This function selects the 'odds' and 'won' columns from the input DataFrame and\n",
    "    returns a new DataFrame containing just these two, aligned by index.\n",
    "\n",
    "    Parameters:\n",
    "        df (pandas.DataFrame): The original DataFrame, expected to contain 'odds' and 'won' columns.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: A new DataFrame with only 'odds' and 'won' columns.\n",
    "    \"\"\"\n",
    "    # Extract columns\n",
    "    odds_col = df.loc[:, 'odds']\n",
    "    won_col = df.loc[:, 'won']\n",
    "\n",
    "    # Create dataframe\n",
    "    odds_win_df = pd.concat([odds_col, won_col], axis=1)\n",
    "\n",
    "    return odds_win_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the function\n",
    "odds_win_df = extract_odds_df(player_match_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use some of the most recent data as our test dataset to ensure there is no data leakage through the model being tested on matches that came before the matches in the training dataset, or through data in the training and test datasets existing for the same match since each match is split by player an opponent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of dataset where matches took place in 2023 or 2024: 14.73%\n"
     ]
    }
   ],
   "source": [
    "pct_23_24 = round((player_match_df['year'].isin([2020, 2021, 2022]).sum() / len(player_match_df)) * 100, 2)\n",
    "print(f'Percentage of dataset where matches took place in 2023 or 2024: {pct_23_24}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to create train/test split\n",
    "\n",
    "Since the data from 2020-2022 accounts for around 15% of our data, this will be a good proportion to use as our test dataset. Therefore we will build a function to split the dataset into a training and test set based on these years, and also make sure we also split our odds dataset on the same indexes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_test_splits(df, odds_win_df):\n",
    "    \"\"\"\n",
    "    Splits the dataset into training and testing sets based on specific years.\n",
    "\n",
    "    This version does not use random sampling. Instead:\n",
    "    - Data from the years 2020, 2021, and 2022 is used for testing.\n",
    "    - All other years are used for training.\n",
    "    - The 'won' and 'odds' columns are removed from the feature set prior to splitting.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pandas.DataFrame): The full DataFrame containing features, including 'year', 'won', and 'odds'.\n",
    "        odds_win_df (pandas.DataFrame): A two-column DataFrame with 'odds' and 'won' values.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A six-part tuple containing:\n",
    "            - X_train (pandas.DataFrame): Training features.\n",
    "            - X_test (pandas.DataFrame): Testing features.\n",
    "            - y_train (pandas.Series): Training target values ('won').\n",
    "            - y_test (pandas.Series): Testing target values ('won').\n",
    "            - odds_win_train (pandas.DataFrame): Training odds and outcomes.\n",
    "            - odds_win_test (pandas.DataFrame): Testing odds and outcomes.\n",
    "    \"\"\"\n",
    "    # Create a copy \n",
    "    df_new = df.copy()\n",
    "\n",
    "    # Remove target and odds columns from feature set\n",
    "    df_new = df_new.drop(columns=['won', 'odds'])\n",
    "\n",
    "    # Split based on year\n",
    "    train_indexes = df_new[~(df_new['year'].isin([2020, 2021, 2022]))].index\n",
    "    test_indexes = df_new[df_new['year'].isin([2020, 2021, 2022])].index\n",
    "\n",
    "    # Define X_train and X_test\n",
    "    X_train = df_new.loc[train_indexes]\n",
    "    X_test = df_new.loc[test_indexes]\n",
    "\n",
    "    # Define odds_win_train and odds_win_test\n",
    "    odds_win_train = odds_win_df.loc[train_indexes]\n",
    "    odds_win_test = odds_win_df.loc[test_indexes]\n",
    "\n",
    "    # Define y_train and y_test \n",
    "    y_train = odds_win_train['won']\n",
    "    y_test = odds_win_test['won']\n",
    "\n",
    "    return X_train, X_test, y_train, y_test, odds_win_train, odds_win_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the function\n",
    "X_train, X_test, y_train, y_test, odds_win_train, odds_win_test = create_train_test_splits(player_match_df, odds_win_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at what features correlate the most with our target variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "won                                             1.000000\n",
       "current_vsTop_win_rate__previous_year_diff      0.341815\n",
       "pts_diff                                        0.317439\n",
       "opp_current_vsTop_win_rate__previous_year       0.304896\n",
       "current_series_win_rate__previous_year_diff     0.302753\n",
       "player_current_vsTop_win_rate__previous_year    0.298852\n",
       "current_vsTop_wins__previous_year_diff          0.298152\n",
       "vsTop50_pct__previous_year_diff                 0.288245\n",
       "vsTop100_pct__previous_year_diff                0.277424\n",
       "grand_slam_pct__previous_year_diff              0.266510\n",
       "main_tour_pct__previous_year_diff               0.266145\n",
       "opp_current_vsTop_wins__previous_year           0.252394\n",
       "masters_pct__previous_year_diff                 0.251940\n",
       "vsTop20_pct__previous_year_diff                 0.248198\n",
       "rank_diff                                       0.241616\n",
       "Name: won, dtype: float64"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View correlation values\n",
    "top_corr_vals = abs(player_match_df.drop(columns='odds').corr()['won']).sort_values(ascending=False)\n",
    "top_corr_vals.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to reduce number of features based on correlation\n",
    "\n",
    "We will now build a function that reduces the number of features iteratively based on set correlation thresholds, and trains a couple of models on each threshold to find the correlation threshold that leads to the best performing model, and returns the filtered dataset based on this optimal threshold:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimise_corr_lim_with_models(X_train, X_test, y_train, y_test):\n",
    "    \"\"\"\n",
    "    Optimises the correlation threshold for feature selection based on model performance.\n",
    "\n",
    "    This function:\n",
    "    - Iteratively tests correlation thresholds (0.01 to 0.24) to filter features based on their\n",
    "      correlation with the target.\n",
    "    - For each threshold, trains two models (XGBoost and Random Forest) using only the filtered features.\n",
    "    - Evaluates each model using AUC (Area Under the ROC Curve).\n",
    "    - Tracks and returns the best-performing model and correlation threshold.\n",
    "    - Returns filtered versions of the training and test sets using the optimal threshold.\n",
    "\n",
    "    Parameters:\n",
    "        X_train (pandas.DataFrame): Training features, including a 'year' column which is removed.\n",
    "        X_test (pandas.DataFrame): Testing features, including a 'year' column which is removed.\n",
    "        y_train (pandas.Series): Training labels (binary classification).\n",
    "        y_test (pandas.Series): Testing labels (binary classification).\n",
    "\n",
    "    Returns:\n",
    "        tuple: A six-part tuple containing:\n",
    "            - best_corr_lim (float): The optimal correlation threshold.\n",
    "            - best_auc (float): The highest AUC score achieved.\n",
    "            - best_model_name (str): The name of the best-performing model.\n",
    "            - X_train_reduced (pandas.DataFrame): Reduced training feature set.\n",
    "            - X_test_reduced (pandas.DataFrame): Reduced testing feature set.\n",
    "            - results_df (pandas.DataFrame): A DataFrame with AUC results for each model and threshold.\n",
    "    \"\"\"\n",
    "    corr_lims = [i / 100 for i in range(2, 25)]  # 0.01 to 0.24\n",
    "\n",
    "    best_corr_lim = None\n",
    "    best_auc = 0\n",
    "    best_model_name = None\n",
    "\n",
    "    X_train_new = X_train.drop(columns=\"year\")\n",
    "    X_test_new = X_test.drop(columns=\"year\")\n",
    "\n",
    "    results = []  # To store results for each model and threshold\n",
    "\n",
    "    for idx, corr_lim in enumerate(corr_lims):\n",
    "        if idx % 10 == 0:\n",
    "            print(f\"Processing iteration {idx} with corr_lim: {corr_lim}\")\n",
    "\n",
    "        # Compute correlations and filter features based on the threshold\n",
    "        correlations = X_train_new.corrwith(y_train)\n",
    "        features_to_use = correlations[abs(correlations) > corr_lim].index.to_list()\n",
    "\n",
    "        if not features_to_use:\n",
    "            print(f\"No features left with corr_lim {corr_lim}. Skipping this iteration.\")\n",
    "            continue\n",
    "\n",
    "        X_train_filtered = X_train_new[features_to_use]\n",
    "        X_test_filtered = X_test_new[features_to_use]\n",
    "\n",
    "        # Define models\n",
    "        models = {\n",
    "            \"XGBoost\": xgb.XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\"),\n",
    "            \"RandomForest\": RandomForestClassifier(random_state=42)\n",
    "        }\n",
    "\n",
    "        for model_name, model in models.items():\n",
    "            # Train and evaluate the model\n",
    "            model.fit(X_train_filtered, y_train)\n",
    "            y_pred = model.predict_proba(X_test_filtered)[:, 1]\n",
    "            auc_score = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "            results.append({\n",
    "                \"corr_lim\": corr_lim,\n",
    "                \"model\": model_name,\n",
    "                \"auc\": auc_score\n",
    "            })\n",
    "\n",
    "            if auc_score > best_auc:\n",
    "                best_auc = auc_score\n",
    "                best_corr_lim = corr_lim\n",
    "                best_model_name = model_name\n",
    "\n",
    "    # Get the best features based on the optimal correlation limit\n",
    "    correlations = X_train_new.corrwith(y_train)\n",
    "    best_features = correlations[abs(correlations) > best_corr_lim].index.to_list()\n",
    "    X_train_reduced = X_train_new[best_features]\n",
    "    X_test_reduced = X_test_new[best_features]\n",
    "\n",
    "    removed_features = X_train.shape[1] - X_train_reduced.shape[1]\n",
    "    print(f\"Number of features removed with corr_lim {best_corr_lim}: {removed_features}\")\n",
    "    print(f\"Best Model: {best_model_name} with AUC: {best_auc}\")\n",
    "\n",
    "    return best_corr_lim, best_auc, best_model_name, X_train_reduced, X_test_reduced, pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing iteration 0 with corr_lim: 0.02\n",
      "Processing iteration 10 with corr_lim: 0.12\n",
      "Processing iteration 20 with corr_lim: 0.22\n",
      "Number of features removed with corr_lim 0.02: 10\n",
      "Best Model: XGBoost with AUC: 0.7248402434737563\n"
     ]
    }
   ],
   "source": [
    "# Run the function\n",
    "best_corr_lim, best_auc, best_model_name, X_train_reduced, X_test_reduced, results = optimise_corr_lim_with_models(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now build a function that does the same as above, but instead removes features based on different thresholds of colinearity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimise_colin_lim_with_models(X_train, X_test, y_train, y_test):\n",
    "    \"\"\"\n",
    "    Optimises the collinearity threshold to remove highly correlated features and selects \n",
    "    the best-performing model based on AUC.\n",
    "\n",
    "    This function:\n",
    "    - Iterates over a range of collinearity limits (from 0.60 to 0.95).\n",
    "    - For each limit, identifies and drops features in the training and test sets that are \n",
    "      highly correlated above the threshold.\n",
    "    - Trains and evaluates two models (Random Forest and XGBoost) on the reduced datasets.\n",
    "    - Selects the model and threshold combination yielding the highest AUC score.\n",
    "    - Applies the optimal collinearity threshold to return final reduced datasets.\n",
    "\n",
    "    Parameters:\n",
    "        X_train (pandas.DataFrame): Training feature set.\n",
    "        X_test (pandas.DataFrame): Testing feature set.\n",
    "        y_train (pandas.Series): Training labels.\n",
    "        y_test (pandas.Series): Testing labels.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A five-part tuple containing:\n",
    "            - best_colin_lim (float): The collinearity threshold that gave the best result.\n",
    "            - best_auc (float): The highest AUC score achieved.\n",
    "            - best_model_name (str): The name of the best-performing model.\n",
    "            - X_train_reduced (pandas.DataFrame): Reduced training dataset.\n",
    "            - X_test_reduced (pandas.DataFrame): Reduced testing dataset.\n",
    "    \"\"\"\n",
    "    colin_lims = [i / 100 for i in range(60, 96)]  # 0.6 to 0.95\n",
    "\n",
    "    best_colin_lim = None\n",
    "    best_auc = 0\n",
    "    best_model_name = None\n",
    "\n",
    "    for idx, colin_lim in enumerate(colin_lims):\n",
    "        if idx % 10 == 0:\n",
    "            print(f\"Processing iteration {idx} with colin_lim: {colin_lim}\")\n",
    "\n",
    "        # Create a correlation matrix\n",
    "        corr_matrix = X_train.corr().abs()\n",
    "\n",
    "        # Select upper triangle of correlation matrix\n",
    "        upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "\n",
    "        # Find features to drop\n",
    "        to_drop = [column for column in upper.columns if any(upper[column] > colin_lim)]\n",
    "\n",
    "        # Drop features from training and validation set\n",
    "        X_train_filtered = X_train.drop(to_drop, axis=1)\n",
    "        X_test_filtered = X_test.drop(to_drop, axis=1)\n",
    "\n",
    "        # Define models\n",
    "        models = {\n",
    "            \"RandomForest\": RandomForestClassifier(random_state=42),\n",
    "            \"XGBoost\": xgb.XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\")\n",
    "        }\n",
    "\n",
    "        for model_name, model in models.items():\n",
    "            # Train model\n",
    "            model.fit(X_train_filtered, y_train)\n",
    "\n",
    "            # Predict and calculate AUC on the validation set\n",
    "            y_pred = model.predict_proba(X_test_filtered)[:, 1]\n",
    "            auc_score = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "            if auc_score > best_auc:\n",
    "                best_auc = auc_score\n",
    "                best_colin_lim = colin_lim\n",
    "                best_model_name = model_name\n",
    "\n",
    "    # Apply best colinearity limit\n",
    "    corr_matrix = X_train.corr().abs()\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "    to_drop = [column for column in upper.columns if any(upper[column] > best_colin_lim)]\n",
    "    X_train_reduced = X_train.drop(to_drop, axis=1)\n",
    "    X_test_reduced = X_test.drop(to_drop, axis=1)\n",
    "\n",
    "    # Print the number of removed features\n",
    "    removed_features = X_train.shape[1] - X_train_reduced.shape[1]\n",
    "    print(f\"Number of features removed with colin_lim {best_colin_lim}: {removed_features}\")\n",
    "    print(f\"Best Model: {best_model_name} with AUC: {best_auc}\")\n",
    "\n",
    "    return best_colin_lim, best_auc, best_model_name, X_train_reduced, X_test_reduced\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing iteration 0 with colin_lim: 0.6\n",
      "Processing iteration 10 with colin_lim: 0.7\n",
      "Processing iteration 20 with colin_lim: 0.8\n",
      "Processing iteration 30 with colin_lim: 0.9\n",
      "Number of features removed with colin_lim 0.7: 203\n",
      "Best Model: RandomForest with AUC: 0.7299330790761107\n",
      "Best Colinearity Limit: 0.7 with AUC: 0.7299330790761107 using model: RandomForest\n"
     ]
    }
   ],
   "source": [
    "# Run the function\n",
    "best_colin_lim, best_auc, best_model_name, X_train, X_test = optimise_colin_lim_with_models(X_train_reduced, X_test_reduced, y_train, y_test)\n",
    "print(\"Best Colinearity Limit:\", best_colin_lim, \"with AUC:\", best_auc, \"using model:\", best_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now view how many columns reamin to build our function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns remaining in X_train: 81\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of columns remaining in X_train: {X_train.shape[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can save these dataframes to files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to files\n",
    "X_train.to_csv(r'train_test_datasets\\X_train.csv', index=False)\n",
    "X_test.to_csv(r'train_test_datasets\\X_test.csv', index=False)\n",
    "y_train.to_csv(r'train_test_datasets\\y_train.csv', index=False)\n",
    "y_test.to_csv(r'train_test_datasets\\y_test.csv', index=False)\n",
    "odds_win_train.to_csv(r'train_test_datasets\\odds_win_train.csv', index=False)\n",
    "odds_win_test.to_csv(r'train_test_datasets\\odds_win_test.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
